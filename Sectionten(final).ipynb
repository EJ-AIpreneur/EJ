{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Oke2m+uNJ3yA+UyCmxx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf25074b5b174e5aaf6f20d3d7a2a267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a731c30bb4ff47d6ace5cd3d32a60029",
              "IPY_MODEL_849c037b9e90475c945ec56691dc2b59",
              "IPY_MODEL_1094e978950b43c5a2bf694d38a24052"
            ],
            "layout": "IPY_MODEL_e7f68de5d1264ecfb7f991efea7ebd3d"
          }
        },
        "a731c30bb4ff47d6ace5cd3d32a60029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c69c51536e4c4987e31cc12c2bb8fd",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9d6e2007df4cf885a2b77460262b30",
            "value": " 70%"
          }
        },
        "849c037b9e90475c945ec56691dc2b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b03b9c033e41439565a6fef1db35e7",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d1b1895aa194403b0bffacb3fa968d4",
            "value": 7
          }
        },
        "1094e978950b43c5a2bf694d38a24052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f154f89c2a4df2a151e87784a49af3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c03ae903c634babab502ec4276be8be",
            "value": " 7/10 [20:56&lt;08:57, 179.21s/it]"
          }
        },
        "e7f68de5d1264ecfb7f991efea7ebd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c69c51536e4c4987e31cc12c2bb8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9d6e2007df4cf885a2b77460262b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8b03b9c033e41439565a6fef1db35e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1b1895aa194403b0bffacb3fa968d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17f154f89c2a4df2a151e87784a49af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c03ae903c634babab502ec4276be8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EJ-AIpreneur/EJ-AIpreneur/blob/main/Sectionten(final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLpixr89Yz22",
        "outputId": "1cddf251-3e0b-46f9-a9a3-5ee4d20d16e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "0.16.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"Couldn't find those for you... Downloading them now.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    print(\"Couldn't find those for you... Downloading them now.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVcPrjKHeAxm",
        "outputId": "490aadff-19a3-4494-ada7-d834066da3e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find those for you... Downloading them now.\n",
            "Couldn't find those for you... Downloading them now.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Counting objects: 100% (1234/1234), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 4056 (delta 1141), reused 1124 (delta 1124), pack-reused 2822\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 649.94 MiB | 35.16 MiB/s, done.\n",
            "Resolving deltas: 100% (2386/2386), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eBXeumCJexzb",
        "outputId": "4154a8e2-b45a-4b6c-aed7-0dbc5069f9e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")\n",
        "\n",
        "data_20_percent_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkeRn0nVe58p",
        "outputId": "2d4c5b11-be58-410e-c524-71a05ad964da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi_20_percent')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = data_20_percent_path / \"train\"\n",
        "test_dir = data_20_percent_path / \"test\"\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW5JhWkifXgt",
        "outputId": "6c79421c-6867-4be2-969f-24fe03124d70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
              " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "def get_state_dict(self, *args, **kwargs):\n",
        "    kwargs.pop(\"check_hash\")\n",
        "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "effnetb2_transforms = effnetb2_weights.transforms()\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "\n",
        "for param in effnetb2.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrqmuhCfe6R",
        "outputId": "1f1b864e-40fb-486a-e878-8412e70ddc51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XkLDgusgc4q",
        "outputId": "8d2d5c31-7173-416c-e4c7-b9249a95b7d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.3, inplace=True)\n",
              "  (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1408, out_features=3)\n",
        ")"
      ],
      "metadata": {
        "id": "buvoykfuhuSp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDymectOh_gi",
        "outputId": "0acf50a7-4cda-419d-8a93-416abf8ab516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.3, inplace=True)\n",
              "  (1): Linear(in_features=1408, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(num_classes: int=3,\n",
        "                          seed: int=42):\n",
        "\n",
        "    def get_state_dict(self, *args, **kwargs):\n",
        "        kwargs.pop(\"check_hash\")\n",
        "        return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "    WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=3)\n",
        "    )\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "kvaFXUlViGdA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2, effnetb2_transforms = create_effnetb2_model(num_classes=3,\n",
        "                                                      seed=42)"
      ],
      "metadata": {
        "id": "kbS4Bnj5iot7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(\n",
        "    model=effnetb2,\n",
        "    input_size=(1, 3, 224, 224),\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    col_width=20,\n",
        "    row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiaWcHRKi5Tx",
        "outputId": "29d45f73-6e56-43c4-a1fd-7fa441bded69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1408, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    │    └─MBConv (1)                                       [1, 16, 112, 112]    [1, 16, 112, 112]    (612)                False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    │    └─MBConv (2)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 48, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 48, 28, 28]      (16,518)             False\n",
              "│    │    └─MBConv (1)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    │    └─MBConv (2)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    └─Sequential (4)                                        [1, 48, 28, 28]      [1, 88, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 48, 28, 28]      [1, 88, 14, 14]      (50,300)             False\n",
              "│    │    └─MBConv (1)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (2)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (3)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    └─Sequential (5)                                        [1, 88, 14, 14]      [1, 120, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 88, 14, 14]      [1, 120, 14, 14]     (149,158)            False\n",
              "│    │    └─MBConv (1)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (2)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (3)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    └─Sequential (6)                                        [1, 120, 14, 14]     [1, 208, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 120, 14, 14]     [1, 208, 7, 7]       (301,406)            False\n",
              "│    │    └─MBConv (1)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (2)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (3)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (4)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    └─Sequential (7)                                        [1, 208, 7, 7]       [1, 352, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 208, 7, 7]       [1, 352, 7, 7]       (846,900)            False\n",
              "│    │    └─MBConv (1)                                       [1, 352, 7, 7]       [1, 352, 7, 7]       (1,888,920)          False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 352, 7, 7]       [1, 1408, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 352, 7, 7]       [1, 1408, 7, 7]      (495,616)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1408, 7, 7]      [1, 1408, 7, 7]      (2,816)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1408, 7, 7]      [1, 1408, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1408, 7, 7]      [1, 1408, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1408]            [1, 3]               --                   True\n",
              "│    └─Dropout (0)                                           [1, 1408]            [1, 1408]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1408]            [1, 3]               4,227                True\n",
              "============================================================================================================================================\n",
              "Total params: 7,705,221\n",
              "Trainable params: 4,227\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (M): 657.64\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.80\n",
              "Params size (MB): 30.82\n",
              "Estimated Total Size (MB): 188.22\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b2_train_dataloader, b2_test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=32,\n",
        "    transform=effnetb2_transforms\n",
        ")\n",
        "len(b2_train_dataloader), len(b2_test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huu0aWI8jDb_",
        "outputId": "8a981b8f-8b37-4330-b088-3cb42988b148"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "optimizer = torch.optim.Adam(effnetb2.parameters(), lr=0.003)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "effnetb2_results = engine.train(\n",
        "    model=effnetb2,\n",
        "    train_dataloader=b2_train_dataloader,\n",
        "    test_dataloader=b2_test_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    epochs=10,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "bf25074b5b174e5aaf6f20d3d7a2a267",
            "a731c30bb4ff47d6ace5cd3d32a60029",
            "849c037b9e90475c945ec56691dc2b59",
            "1094e978950b43c5a2bf694d38a24052",
            "e7f68de5d1264ecfb7f991efea7ebd3d",
            "57c69c51536e4c4987e31cc12c2bb8fd",
            "fe9d6e2007df4cf885a2b77460262b30",
            "d8b03b9c033e41439565a6fef1db35e7",
            "8d1b1895aa194403b0bffacb3fa968d4",
            "17f154f89c2a4df2a151e87784a49af3",
            "3c03ae903c634babab502ec4276be8be"
          ]
        },
        "id": "NUyOGcEbjwMd",
        "outputId": "a0a35655-d315-4ad7-c7ee-d75d7901ffed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf25074b5b174e5aaf6f20d3d7a2a267"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.8375 | train_acc: 0.6354 | test_loss: 0.4332 | test_acc: 0.8585\n",
            "Epoch: 2 | train_loss: 0.4557 | train_acc: 0.8562 | test_loss: 0.2993 | test_acc: 0.9443\n",
            "Epoch: 3 | train_loss: 0.3325 | train_acc: 0.8979 | test_loss: 0.2661 | test_acc: 0.9534\n",
            "Epoch: 4 | train_loss: 0.3971 | train_acc: 0.8771 | test_loss: 0.2453 | test_acc: 0.9597\n",
            "Epoch: 5 | train_loss: 0.3318 | train_acc: 0.8792 | test_loss: 0.2389 | test_acc: 0.9534\n",
            "Epoch: 6 | train_loss: 0.2165 | train_acc: 0.9479 | test_loss: 0.2323 | test_acc: 0.9625\n",
            "Epoch: 7 | train_loss: 0.2795 | train_acc: 0.9021 | test_loss: 0.2124 | test_acc: 0.9506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(effnetb2_results)"
      ],
      "metadata": {
        "id": "M--WXkBbkfbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "utils.save_model(model=effnetb2,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"effnetb2_train_on_20_percent_pizza_steak_sushi.pth\")"
      ],
      "metadata": {
        "id": "DE9mECoiknpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pretrained_effnetb2_model_size = Path(\"models/effnetb2_train_on_20_percent_pizza_steak_sushi.pth\").stat().st_size // (1024 * 1024)\n",
        "print(f\"The size of the pretrained effnetb2 model: {pretrained_effnetb2_model_size} MB\")"
      ],
      "metadata": {
        "id": "4jFG8-vKk46t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "GHr7LXMhlTTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
        "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
        "                  \"number_of_parameters\": effnetb2_total_params,\n",
        "                  \"model_size\": pretrained_effnetb2_model_size}\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "iB89vnHjlgWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit = torchvision.models.vit_b_16()\n",
        "vit.heads"
      ],
      "metadata": {
        "id": "7dRvp5nTmCMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(num_classes: int=3,\n",
        "                     seed: int=42):\n",
        "\n",
        "    def get_state_dict(self, *args, **kwargs):\n",
        "        kwargs.pop(\"check_hash\")\n",
        "        return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "    WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "    weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.heads = nn.Sequential(\n",
        "        nn.Linear(in_features=768,\n",
        "                  out_features=num_classes)\n",
        "    )\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "YONKjPJlmHV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit, vit_transforms = create_vit_model(num_classes=3,\n",
        "                                       seed=42)"
      ],
      "metadata": {
        "id": "9f8EcPtH1NuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(\n",
        "    model=vit,\n",
        "    input_size=(1, 3, 224, 224),\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    col_width=20,\n",
        "    row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "AmXmPbUI1Ui-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_train_datloader, vit_test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=vit_transforms,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "WrF-XxhS1r7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "optimizer = torch.optim.Adam(vit.parameters(), lr=0.003)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "vit_results = engine.train(\n",
        "    model = vit,\n",
        "    train_dataloader=vit_train_datloader,\n",
        "    test_dataloader=vit_test_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    epochs=10,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "cWFFAnF41mmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(vit_results)"
      ],
      "metadata": {
        "id": "PFtYTR312mAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "utils.save_model(model=vit,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"vit_model_train_20_percent_pizza_steak_sushi.pth\")"
      ],
      "metadata": {
        "id": "Se2ZnLef3BEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "vit_model_size = Path(\"models/vit_model_train_20_percent_pizza_steak_sushi.pth\").stat().st_size // (1024 * 1024)\n",
        "print(f\"Vit model size {vit_model_size} MB\")"
      ],
      "metadata": {
        "id": "XEknJo7f26gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_total_params = sum(torch.numel(param) for param in vit.parameters())\n",
        "vit_total_params"
      ],
      "metadata": {
        "id": "5KbocJlJ36_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats = {\"test_loss\": vit_results[\"test_loss\"][-1],\n",
        "             \"test_acc\": vit_results[\"test_acc\"][-1],\n",
        "             \"number_of_parameters\": vit_total_params,\n",
        "             \"model_size\": vit_model_size}\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "Fz5O1-PO4Hmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"Finding all filepaths ending with '.jpg' in directorys...\")\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_data_paths[:5]"
      ],
      "metadata": {
        "id": "JcFiGq2Y5Dzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict\n",
        "\n",
        "def pred_and_store(paths: List[pathlib.Path],\n",
        "                   model: torch.nn.Module,\n",
        "                   transform: torchvision.transforms,\n",
        "                   class_names: List[str],\n",
        "                   device: str=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "\n",
        "    pred_list = []\n",
        "\n",
        "    for path in tqdm(paths):\n",
        "        pred_dict = {}\n",
        "\n",
        "        pred_dict[\"image_path\"] = path\n",
        "        class_name = path.parent.stem\n",
        "        pred_dict[\"class_name\"] = class_name\n",
        "\n",
        "        start_time = timer()\n",
        "\n",
        "        img = Image.open(path)\n",
        "\n",
        "        transform_img = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            pred_logit = model(transform_img)\n",
        "            pred_prob = torch.softmax(pred_logit, dim=1)\n",
        "            pred_label = torch.argmax(pred_prob, dim=1)\n",
        "            pred_class = class_names[pred_label.cpu()]\n",
        "\n",
        "            pred_dict[\"pred_prob\"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)\n",
        "            pred_dict[\"pred_class\"] = pred_class\n",
        "\n",
        "            end_time = timer()\n",
        "            pred_dict[\"time_for_pred\"] = round(end_time-start_time, 4)\n",
        "\n",
        "        pred_dict[\"correct\"] = class_name == pred_class\n",
        "\n",
        "        pred_list.append(pred_dict)\n",
        "\n",
        "    return pred_list"
      ],
      "metadata": {
        "id": "-HdEUtGS47vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts = pred_and_store(\n",
        "    paths=test_data_paths,\n",
        "    model=effnetb2,\n",
        "    transform=effnetb2_transforms,\n",
        "    class_names=class_names,\n",
        "    device=\"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "5KDzJbCk8ncv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts[:2]"
      ],
      "metadata": {
        "id": "izGIM8l-9KCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hold how many correct guesses\n",
        "correct_count = 0\n",
        "\n",
        "#Tterate through each prediction\n",
        "for pred_dict in effnetb2_test_pred_dicts:\n",
        "\n",
        "    #Set guess equal to the \"correct\" instance in the dictionary\n",
        "    guess = pred_dict[\"correct\"]\n",
        "\n",
        "    #If guess if true then add 1 to the correct guess count\n",
        "    if guess == True:\n",
        "        correct_count += 1\n",
        "\n",
        "#print how many guesses were correct\n",
        "print(correct_count)"
      ],
      "metadata": {
        "id": "kgJL12A_9kPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)\n",
        "effnetb2_test_pred_df.head()"
      ],
      "metadata": {
        "id": "_JuZVaPa-82Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "P3D-7J_d_aIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"The average time per predection: {effnetb2_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "44YmmfWE_q12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats[\"time_per_pred_cpu\"] = effnetb2_average_time_per_pred\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "v3BJs_vO_8Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_dicts = pred_and_store(paths=test_data_paths,\n",
        "                                     model=vit,\n",
        "                                     transform=vit_transforms,\n",
        "                                     class_names=class_names,\n",
        "                                     device=\"cpu\")\n"
      ],
      "metadata": {
        "id": "0XRuscRaAaok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_dicts[:2]"
      ],
      "metadata": {
        "id": "MUILq63jAp0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "vit_pred_df = pd.DataFrame(vit_test_pred_dicts)\n",
        "vit_pred_df.head()"
      ],
      "metadata": {
        "id": "w-623vZoBBwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "4BYWOiyiBQaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_average_time_per_pred = round(vit_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"Your average time per prediction with vit: {vit_average_time_per_pred}\")"
      ],
      "metadata": {
        "id": "_ZD3N8ngBaMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats[\"time_per_pred_cpu\"] = vit_average_time_per_pred\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "nLLko-dxB3cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([effnetb2_stats, vit_stats])\n",
        "\n",
        "df[\"model\"] = [\"EffnetB2\", \"ViT\"]\n",
        "\n",
        "df[\"test_acc\"] = round(df[\"test_acc\"] * 100, 2)\n",
        "df"
      ],
      "metadata": {
        "id": "FzXJcI9CCE_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare ViT to EffNetB2 across different characteristics\n",
        "pd.DataFrame(data=(df.set_index(\"model\").loc[\"ViT\"] / df.set_index(\"model\").loc[\"EffnetB2\"]), # divide ViT statistics by EffNetB2 statistics\n",
        "             columns=[\"ViT to EffNetB2 ratios\"]).T"
      ],
      "metadata": {
        "id": "M1jOi2hTD7uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "Dt7ud1AUEUyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"model_size\"])"
      ],
      "metadata": {
        "id": "pJziRjHvEXL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a plot from model comparison DataFrame\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "scatter = ax.scatter(data=df,\n",
        "                     x=\"time_per_pred_cpu\",\n",
        "                     y=\"test_acc\",\n",
        "                     c=[\"blue\", \"orange\"], # what colours to use?\n",
        "                     s=\"model_size\") # size the dots by the model sizes\n",
        "\n",
        "# 2. Add titles, labels and customize fontsize for aesthetics\n",
        "ax.set_title(\"FoodVision Mini Inference Speed vs Performance\", fontsize=18)\n",
        "ax.set_xlabel(\"Prediction time per image (seconds)\", fontsize=14)\n",
        "ax.set_ylabel(\"Test accuracy (%)\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.grid(True)\n",
        "\n",
        "# 3. Annotate with model names\n",
        "for index, row in df.iterrows():\n",
        "    ax.annotate(text=row[\"model\"], # note: depending on your version of Matplotlib, you may need to use \"s=...\" or \"text=...\", see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270\n",
        "                xy=(row[\"time_per_pred_cpu\"]+0.0006, row[\"test_acc\"]+0.03),\n",
        "                size=12)\n",
        "\n",
        "# 4. Create a legend based on model sizes\n",
        "handles, labels = scatter.legend_elements(prop=\"sizes\", alpha=0.5)\n",
        "model_size_legend = ax.legend(handles,\n",
        "                              labels,\n",
        "                              loc=\"lower right\",\n",
        "                              title=\"Model size\",\n",
        "                              fontsize=12)\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"images/09-foodvision-mini-inference-speed-vs-performance.jpg\")\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzapQBU8Csq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import gradio as gr\n",
        "except:\n",
        "    !pip -q install gradio\n",
        "    import gradio as gr\n",
        "\n",
        "print(f\"gradio version: {gr.__version__}\")"
      ],
      "metadata": {
        "id": "qn0POZBxFm9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}